#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Simulate the full multi-model processing pipeline
æ¨¡æ“¬å®Œæ•´çš„å¤šæ¨¡å‹è™•ç†æµç¨‹
"""

import pandas as pd
import sys
import os
import io

# æ·»åŠ apiç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('api')

def simulate_full_processing():
    """æ¨¡æ“¬å®Œæ•´çš„å¤šæ¨¡å‹è™•ç†æµç¨‹"""
    
    print("=" * 60)
    print("æ¨¡æ“¬å®Œæ•´çš„å¤šæ¨¡å‹è™•ç†æµç¨‹")
    print("=" * 60)
    
    test_file = "data/multi_model_test_proper.xlsx"
    
    if not os.path.exists(test_file):
        print(f"âŒ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨: {test_file}")
        return
    
    # æ­¥é©Ÿ1: è®€å–æª”æ¡ˆå…§å®¹
    print("ğŸ“Š æ­¥é©Ÿ1: è®€å–æª”æ¡ˆå…§å®¹")
    with open(test_file, 'rb') as f:
        file_content = f.read()
    print(f"æª”æ¡ˆå¤§å°: {len(file_content)} bytes")
    
    # æ­¥é©Ÿ2: æ¨¡æ“¬ _read_excel_from_memory
    print(f"\nğŸ“Š æ­¥é©Ÿ2: æ¨¡æ“¬ _read_excel_from_memory")
    df = read_excel_from_memory(file_content)
    
    if df is None:
        print("âŒ ç„¡æ³•è®€å–Excelæª”æ¡ˆ")
        return
    
    print(f"è®€å–çµæœ: {len(df)} è¡Œ x {len(df.columns)} æ¬„")
    
    # æ­¥é©Ÿ3: æ¨¡æ“¬æ¨¡å‹åˆ†å‰²
    print(f"\nğŸ“Š æ­¥é©Ÿ3: æ¨¡æ“¬æ¨¡å‹åˆ†å‰²")
    model_blocks = split_models_from_dataframe(df)
    
    if not model_blocks:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹")
        return
    
    print(f"æ‰¾åˆ° {len(model_blocks)} å€‹æ¨¡å‹: {list(model_blocks.keys())}")
    
    # æ­¥é©Ÿ4: æ¨¡æ“¬æ¯å€‹æ¨¡å‹çš„è™•ç†
    print(f"\nğŸ“Š æ­¥é©Ÿ4: æ¨¡æ“¬æ¯å€‹æ¨¡å‹çš„è™•ç†")
    
    successful_models = 0
    
    for model_name, model_df in model_blocks.items():
        print(f"\nğŸ” è™•ç†æ¨¡å‹: {model_name}")
        print(f"  è³‡æ–™å¤§å°: {len(model_df)} è¡Œ x {len(model_df.columns)} æ¬„")
        
        try:
            # æ¨¡æ“¬æ¬„ä½é©—è­‰
            mappings = validate_and_map_columns(model_df)
            
            if mappings:
                print(f"  âœ… æ¬„ä½é©—è­‰æˆåŠŸ: {mappings}")
                
                # æ¨¡æ“¬è©•ä¼°éç¨‹
                print(f"  ğŸ”„ æ¨¡æ“¬è©•ä¼°éç¨‹...")
                
                # æª¢æŸ¥è³‡æ–™å“è³ª
                data_quality_ok = check_data_quality(model_df, mappings)
                
                if data_quality_ok:
                    print(f"  âœ… è³‡æ–™å“è³ªæª¢æŸ¥é€šé")
                    successful_models += 1
                else:
                    print(f"  âŒ è³‡æ–™å“è³ªæª¢æŸ¥å¤±æ•—")
                    
            else:
                print(f"  âŒ æ¬„ä½é©—è­‰å¤±æ•—")
                
        except Exception as e:
            print(f"  âŒ è™•ç†å¤±æ•—: {e}")
    
    # ç¸½çµ
    print(f"\nğŸ“Š è™•ç†ç¸½çµ:")
    print(f"ç¸½æ¨¡å‹æ•¸: {len(model_blocks)}")
    print(f"æˆåŠŸè™•ç†: {successful_models}")
    print(f"å¤±æ•—æ•¸é‡: {len(model_blocks) - successful_models}")
    
    if successful_models > 0:
        print(f"âœ… å¤šæ¨¡å‹è™•ç†æ‡‰è©²æˆåŠŸ")
    else:
        print(f"âŒ æ‰€æœ‰æ¨¡å‹éƒ½è™•ç†å¤±æ•—")

def read_excel_from_memory(file_content: bytes):
    """æ¨¡æ“¬ _read_excel_from_memory æ–¹æ³•"""
    
    try:
        # é¦–å…ˆå˜—è©¦è®€å–å®Œæ•´çš„åŸå§‹è³‡æ–™ï¼ˆheader=Noneï¼‰ä¾†æª¢æŸ¥æ˜¯å¦ç‚ºå¤šæ¨¡å‹æª”æ¡ˆ
        file_buffer = io.BytesIO(file_content)
        raw_df = pd.read_excel(file_buffer, engine='openpyxl', header=None)
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å¤šå€‹æ¨¡å‹
        model_count = 0
        for idx, row in raw_df.iterrows():
            row_values = [str(cell).strip() if pd.notna(cell) else '' for cell in row]
            for cell_value in row_values:
                if cell_value:
                    cell_lower = cell_value.lower()
                    model_keywords = ['gemini', 'gemma', 'chatgpt', 'claude', 'gpt', 'llama', 'palm', 'bard']
                    if any(keyword in cell_lower for keyword in model_keywords):
                        model_count += 1
                        break
        
        print(f"åµæ¸¬åˆ° {model_count} å€‹æ¨¡å‹åç¨±")
        
        # å¦‚æœåµæ¸¬åˆ°å¤šå€‹æ¨¡å‹ï¼Œè¿”å›åŸå§‹è³‡æ–™ï¼ˆheader=Noneï¼‰
        if model_count > 1:
            print("åµæ¸¬åˆ°å¤šæ¨¡å‹æª”æ¡ˆï¼Œä½¿ç”¨åŸå§‹è³‡æ–™æ ¼å¼")
            return raw_df
        
        print("åµæ¸¬åˆ°å–®æ¨¡å‹æª”æ¡ˆï¼Œä½¿ç”¨æ™ºèƒ½æ¨™é¡Œåµæ¸¬")
        # é€™è£¡å¯ä»¥åŠ å…¥å–®æ¨¡å‹çš„è™•ç†é‚è¼¯
        return raw_df
        
    except Exception as e:
        print(f"è®€å–Excelæª”æ¡ˆå¤±æ•—: {e}")
        return None

def split_models_from_dataframe(df: pd.DataFrame):
    """æ¨¡æ“¬æ¨¡å‹åˆ†å‰²é‚è¼¯"""
    
    model_blocks = {}
    current_model = None
    current_header_row = None
    block_rows = []
    
    for idx, row in df.iterrows():
        # æª¢æŸ¥æ¯ä¸€è¡Œæ˜¯å¦ç‚ºæ¨¡å‹åç¨±
        row_values = [str(cell).strip() if pd.notna(cell) else '' for cell in row]
        found_model = None
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ¨¡å‹é—œéµå­—
        for cell_value in row_values:
            if cell_value:
                cell_lower = cell_value.lower()
                model_keywords = ['gemini', 'gemma', 'chatgpt', 'claude', 'gpt', 'llama', 'palm', 'bard']
                if any(keyword in cell_lower for keyword in model_keywords):
                    found_model = cell_value
                    print(f"ç¬¬ {idx + 1} è¡Œç™¼ç¾æ¨¡å‹åç¨±: {found_model}")
                    break
        
        if found_model:
            # å¦‚æœæœ‰å‰ä¸€å€‹æ¨¡å‹ï¼Œå„²å­˜å…¶ block
            if current_model and block_rows:
                if len(block_rows) > 0:
                    # å»ºç«‹DataFrameï¼Œä½¿ç”¨é©ç•¶çš„header
                    if current_header_row is not None and len(block_rows) > 1:
                        # ä½¿ç”¨æ‰¾åˆ°çš„headerè¡Œ
                        model_df = pd.DataFrame(block_rows[1:], columns=block_rows[0])
                    else:
                        # ä½¿ç”¨åŸå§‹æ¬„ä½åç¨±
                        model_df = pd.DataFrame(block_rows, columns=df.columns)
                    
                    # éæ¿¾æ‰ç©ºè¡Œ
                    model_df = model_df.dropna(how='all')
                    if len(model_df) > 0:
                        model_blocks[current_model] = model_df
                        print(f"æ¨¡å‹ {current_model} åŒ…å« {len(model_df)} ç­†è³‡æ–™")
                
                block_rows = []
                current_header_row = None
            
            current_model = found_model
            continue
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºheaderè¡Œï¼ˆåŒ…å«æ¬„ä½é—œéµå­—ï¼‰
        if current_model and not current_header_row:
            header_keywords = ['ç·¨è™Ÿ', 'å—ç·¨', 'éšœç¤™', 'é¡åˆ¥', 'ICD', 'å‚™è¨»', 'è­‰æ˜', 'æ‰‹å†Š']
            has_header_keywords = sum(1 for cell in row_values if any(keyword in str(cell) for keyword in header_keywords))
            
            if has_header_keywords >= 3:  # è‡³å°‘åŒ…å«3å€‹é—œéµå­—æ‰èªç‚ºæ˜¯header
                current_header_row = idx
                block_rows.append(row_values)
                print(f"ç¬¬ {idx + 1} è¡Œè¢«è­˜åˆ¥ç‚ºæ¨¡å‹ {current_model} çš„headerè¡Œ")
                continue
        
        # å¦‚æœæ˜¯è³‡æ–™è¡Œï¼ŒåŠ å…¥ç›®å‰æ¨¡å‹çš„ block
        if current_model:
            # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„è³‡æ–™è¡Œï¼ˆè‡³å°‘æœ‰ä¸€å€‹éç©ºå€¼ï¼‰
            if any(str(cell).strip() for cell in row_values if pd.notna(cell)):
                block_rows.append(row_values)
    
    # è™•ç†æœ€å¾Œä¸€å€‹æ¨¡å‹
    if current_model and block_rows:
        if len(block_rows) > 0:
            if current_header_row is not None and len(block_rows) > 1:
                # ä½¿ç”¨æ‰¾åˆ°çš„headerè¡Œ
                model_df = pd.DataFrame(block_rows[1:], columns=block_rows[0])
            else:
                # ä½¿ç”¨åŸå§‹æ¬„ä½åç¨±
                model_df = pd.DataFrame(block_rows, columns=df.columns)
            
            # éæ¿¾æ‰ç©ºè¡Œ
            model_df = model_df.dropna(how='all')
            if len(model_df) > 0:
                model_blocks[current_model] = model_df
                print(f"æ¨¡å‹ {current_model} åŒ…å« {len(model_df)} ç­†è³‡æ–™")
    
    print(f"æ¨¡å‹åˆ†å‰²å®Œæˆï¼Œç¸½å…±æ‰¾åˆ° {len(model_blocks)} å€‹æ¨¡å‹: {list(model_blocks.keys())}")
    return model_blocks

def validate_and_map_columns(df: pd.DataFrame):
    """æ¨¡æ“¬æ¬„ä½é©—è­‰å’Œæ˜ å°„"""
    
    columns = list(df.columns)
    mappings = {}
    
    # å°‹æ‰¾éšœç¤™ç­‰ç´šæ¬„ä½
    disability_level_cols = []
    for i, col in enumerate(columns):
        col_str = str(col).strip()
        if 'éšœç¤™ç­‰ç´š' in col_str:
            disability_level_cols.append((i, col))
    
    # å°‹æ‰¾éšœç¤™é¡åˆ¥æ¬„ä½
    disability_category_cols = []
    for i, col in enumerate(columns):
        col_str = str(col).strip()
        if 'éšœç¤™é¡åˆ¥' in col_str:
            disability_category_cols.append((i, col))
    
    # å°‹æ‰¾ICDè¨ºæ–·æ¬„ä½
    icd_diagnosis_cols = []
    for i, col in enumerate(columns):
        col_str = str(col).strip()
        if 'ICDè¨ºæ–·' in col_str or 'ICD' in col_str:
            icd_diagnosis_cols.append((i, col))
    
    # æ ¹æ“šä½ç½®åˆ¤æ–·æ­£é¢(æ­£ç¢ºç­”æ¡ˆ)å’Œåé¢(AIé æ¸¬)
    if len(disability_level_cols) >= 2:
        correct_col = disability_level_cols[0][1]
        predicted_col = disability_level_cols[1][1]
        mappings['éšœç¤™ç­‰ç´š'] = (correct_col, predicted_col)
    
    if len(disability_category_cols) >= 2:
        correct_col = disability_category_cols[0][1]
        predicted_col = disability_category_cols[1][1]
        mappings['éšœç¤™é¡åˆ¥'] = (correct_col, predicted_col)
    
    if len(icd_diagnosis_cols) >= 2:
        correct_col = icd_diagnosis_cols[0][1]
        predicted_col = icd_diagnosis_cols[1][1]
        mappings['ICDè¨ºæ–·'] = (correct_col, predicted_col)
    
    # å¦‚æœæ‰¾åˆ°è‡³å°‘2å€‹æ˜ å°„ï¼Œèªç‚ºé©—è­‰æˆåŠŸ
    if len(mappings) >= 2:
        return mappings
    
    return None

def check_data_quality(df: pd.DataFrame, mappings: dict):
    """æª¢æŸ¥è³‡æ–™å“è³ª"""
    
    for field_name, (correct_col, predicted_col) in mappings.items():
        # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨
        if correct_col not in df.columns or predicted_col not in df.columns:
            print(f"    âŒ æ¬„ä½ä¸å­˜åœ¨: {correct_col} æˆ– {predicted_col}")
            return False
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
        correct_data = df[correct_col].dropna()
        predicted_data = df[predicted_col].dropna()
        
        if len(correct_data) == 0 or len(predicted_data) == 0:
            print(f"    âŒ æ¬„ä½ {field_name} æ²’æœ‰æœ‰æ•ˆè³‡æ–™")
            return False
    
    return True

if __name__ == "__main__":
    simulate_full_processing()
